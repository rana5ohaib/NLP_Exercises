{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import collections\n",
    "\n",
    "\n",
    "f = []\n",
    "fof = []\n",
    "final =[]\n",
    "tagged = brown.tagged_words()\n",
    "\n",
    "\n",
    "#-------------------------------------\n",
    "#Solution - 1\n",
    "for i in tagged:\n",
    "    f.append(tagged.count(i))\n",
    "    \n",
    "    \n",
    "for i in f:\n",
    "    if (i in final):\n",
    "        continue\n",
    "    final.append(i)\n",
    "    fof.append(f.count(i))\n",
    " \n",
    "\n",
    "fof.sort(reverse=True)\n",
    "print(fof)\n",
    "#-------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------\n",
    "#Solution - 2\n",
    "frequency = collections.Counter(tagged)\n",
    "fof = collections.Counter(frequency.values())\n",
    "\n",
    "print(fof)\n",
    "#-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "simple\n",
      "similar\n",
      "some\n",
      "seeing\n",
      "s562\n",
      "somewhat\n",
      "small\n",
      "semantics\n",
      "sensors\n",
      "summary\n",
      "single\n",
      "simulate\n",
      "swinging\n",
      "something\n",
      "sensitive\n",
      "symptoms\n",
      "snsp\n",
      "smart\n",
      "fit\n",
      "football\n",
      "feature\n",
      "federal\n",
      "features\n",
      "feitico\n",
      "feedback\n",
      "feedforward\n",
      "regulatory\n",
      "region\n",
      "reach\n",
      "right\n",
      "regeneration\n",
      "recording\n",
      "rights\n",
      "reasoning\n",
      "received\n",
      "recall\n",
      "reciprocal\n",
      "rigorous\n",
      "r215\n",
      "reasonable\n",
      "respectively\n",
      "recently\n",
      "resistance\n",
      "restricted\n",
      "require\n",
      "requirements\n",
      "receive\n",
      "roosevelt\n",
      "regular\n",
      "resolve\n",
      "expected\n",
      "extrapolating\n",
      "examples\n",
      "exclusion\n",
      "existing\n",
      "excellent\n",
      "excluding\n",
      "established\n",
      "exists\n",
      "exist\n",
      "e200\n",
      "exception\n",
      "expand\n",
      "explored\n",
      "easily\n",
      "examine\n",
      "experiments\n",
      "exercised\n",
      "economic\n",
      "equilibrium\n",
      "examined\n",
      "easier\n",
      "equip\n",
      "exacerbated\n",
      "impact\n",
      "in\n",
      "into\n",
      "interventions\n",
      "i516\n",
      "initial\n",
      "indicate\n",
      "incorporation\n",
      "influence\n",
      "incompatible\n",
      "institution\n",
      "intentions\n",
      "inclusion\n",
      "independent\n",
      "inertia\n",
      "inherent\n",
      "infant\n",
      "inner\n",
      "image\n",
      "innovations\n",
      "inexperienced\n",
      "t140\n",
      "tables\n",
      "tv\n",
      "typically\n",
      "types\n",
      "form\n",
      "furthermore\n",
      "f620\n",
      "for\n",
      "forward\n",
      "first\n",
      "frequency\n",
      "formed\n",
      "fortunes\n",
      "frp\n",
      "forms\n",
      "forthcoming\n",
      "framework\n",
      "forbidden\n",
      "formal\n",
      "fertility\n",
      "frazier\n",
      "gonzalez\n",
      "gain\n",
      "general\n",
      "gaining\n",
      "gained\n",
      "gandus\n",
      "generic\n",
      "gender\n",
      "g563\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "file = open(\"/Users/ranasohaib/Documents/Sohaib/OneDrive/Documents/7th Semester/NLP/s2/Lab/A2/A2 Maam data/corpus.txt\",\"r\")\n",
    "string = file.read()\n",
    "\n",
    "tokenized = nltk.word_tokenize(string)\n",
    "\n",
    "eD = edit_distance(\"mapping\", \"mappingstuv\")\n",
    "print(eD)\n",
    "\n",
    "def soundex(query: str):\n",
    "    \"\"\"\n",
    "    https://en.wikipedia.org/wiki/Soundex\n",
    "    :param query:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 0: Clean up the query string\n",
    "    query = query.lower()\n",
    "    letters = [char for char in query if char.isalpha()]\n",
    "\n",
    "    # Step 1: Save the first letter. Remove all occurrences of a, e, i, o, u, y, h, w.\n",
    "\n",
    "    # If query contains only 1 letter, return query+\"000\" (Refer step 5)\n",
    "    if len(query) == 1:\n",
    "        return query + \"000\"\n",
    "\n",
    "    to_remove = ('a', 'e', 'i', 'o', 'u', 'y', 'h', 'w')\n",
    "\n",
    "    first_letter = letters[0]\n",
    "    letters = letters[1:]\n",
    "    letters = [char for char in letters if char not in to_remove]\n",
    "\n",
    "    if len(letters) == 0:\n",
    "        return first_letter + \"000\"\n",
    "\n",
    "    # Step 2: Replace all consonants (include the first letter) with digits according to rules\n",
    "\n",
    "    to_replace = {('b', 'f', 'p', 'v'): 1, ('c', 'g', 'j', 'k', 'q', 's', 'x', 'z'): 2,\n",
    "                  ('d', 't'): 3, ('l',): 4, ('m', 'n'): 5, ('r',): 6}\n",
    "\n",
    "    first_letter = [value if first_letter else first_letter for group, value in to_replace.items()\n",
    "                    if first_letter in group]\n",
    "    letters = [value if char else char\n",
    "               for char in letters\n",
    "               for group, value in to_replace.items()\n",
    "               if char in group]\n",
    "\n",
    "    # Step 3: Replace all adjacent same digits with one digit.\n",
    "    letters = [char for ind, char in enumerate(letters)\n",
    "               if (ind == len(letters) - 1 or (ind+1 < len(letters) and char != letters[ind+1]))]\n",
    "\n",
    "    # Step 4: If the saved letterâ€™s digit is the same the resulting first digit, remove the digit (keep the letter)\n",
    "    if first_letter == letters[0]:\n",
    "        letters[0] = query[0]\n",
    "    else:\n",
    "        letters.insert(0, query[0])\n",
    "\n",
    "    # Step 5: Append 3 zeros if result contains less than 3 digits.\n",
    "    # Remove all except first letter and 3 digits after it.\n",
    "\n",
    "    first_letter = letters[0]\n",
    "    letters = letters[1:]\n",
    "\n",
    "    letters = [char for char in letters if isinstance(char, int)][0:3]\n",
    "\n",
    "    while len(letters) < 3:\n",
    "        letters.append(0)\n",
    "\n",
    "    letters.insert(0, first_letter)\n",
    "\n",
    "    string = \"\".join([str(l) for l in letters])\n",
    "\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dict_corpus = { }\n",
    "\n",
    "for i in tokenized:\n",
    "    dict_corpus[soundex(i)] = i\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "list_sample = [\"Sommarized\", \"Fedility\", \"Responded\", \"Esuac\", \"Imnport\", \"Table,\", \"Firous\", \"Fort\", \"Gnertion\"]\n",
    "dict_sample = { }\n",
    "\n",
    "for i in list_sample:\n",
    "    dict_sample[soundex(i)] = i\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "found_already = []\n",
    "        \n",
    "    \n",
    "for i in dict_sample:\n",
    "    \n",
    "    for j in dict_corpus:\n",
    "        \n",
    "        if (j in found_already):\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            if (i == j):\n",
    "                print(dict_corpus.get(j))\n",
    "                found_already.append(j)\n",
    "                \n",
    "            else:\n",
    "                if (j.startswith(i[:3])):\n",
    "                    print(dict_corpus.get(j))\n",
    "                    found_already.append(j)\n",
    "                \n",
    "                else:\n",
    "                    if (j.startswith(i[:2])):\n",
    "                        print(dict_corpus.get(j))\n",
    "                        found_already.append(j)\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarized\n",
      "ability\n",
      "response\n",
      "such\n",
      "support\n",
      "table\n",
      "groups\n",
      "not\n",
      "notion\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "file = open(\"/Users/ranasohaib/Documents/Sohaib/OneDrive/Documents/7th Semester/NLP/s2/Lab/A2/A2 Maam data/corpus.txt\",\"r\")\n",
    "string = file.read()\n",
    "\n",
    "tokenized = nltk.word_tokenize(string)\n",
    "\n",
    "final = []\n",
    "\n",
    "for i in tokenized:\n",
    "    if (i in final):\n",
    "        continue\n",
    "    else:\n",
    "        final.append(i)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "list_sample = [\"Sommarized\", \"Fedility\", \"Responded\", \"Esuac\", \"Imnport\", \"Table,\", \"Firous\", \"Fort\", \"Gnertion\"]\n",
    "eD=10\n",
    "res=\"\"\n",
    "\n",
    "for i in list_sample:\n",
    "    eD=10\n",
    "    for j in final:\n",
    "        if (edit_distance(i, j) < eD):\n",
    "            eD=edit_distance(i,j)\n",
    "            res=j\n",
    "    \n",
    "    print(res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
